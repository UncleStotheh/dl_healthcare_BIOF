{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Week3_4_HW_SH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UncleStotheh/dl_healthcare_BIOF/blob/master/Week3_4_HW_SH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NNRvm7Tm3Jm"
      },
      "source": [
        "#I decided to follow the tutorial for the Age Regression model using MR images\n",
        "#the scripts used were gathered from here: \n",
        "#https://github.com/DLTK/DLTK/tree/master/examples/applications/IXI_HH_age_regression_resnet\n",
        "\n",
        "#i originally tried using my local computer to download and train the algorithm\n",
        "#but i was running into several issues with simply downloading the data\n",
        "#I managed to resolve the main issue which was that the downloading script was \n",
        "  ##downloading incomplete data (potentially corrupted) \n",
        "#Next I tried training the algorithm on my local computer, but it took a long time (low GPU + limited resources)\n",
        "\n",
        "#TLDR: I copied my local jupyter notebook to google collab and decided to use the provided trained algorithm\n",
        "\n",
        "#here are my past attempts and output once I used the pre-trained algorithm \n",
        "\n",
        "#collab attempt:\n",
        "#I ran into issues since a module called tensorflow.contrib is no longer available (even after downgrading tensorflow)\n",
        "#I had to find the original source code for various tensorflow.contrib command/packages\n",
        "#hence why there are so many scripts here \n",
        "#i downloaded the demographic.csv file independently and uploaded from my local computer\n",
        "#due to very slow and tedious downloading/processing of data\n",
        "#i downloaded only the files for sample IXI566 locally and uploaded from my local computer\n",
        "#the age regression output is found below\n",
        "\n",
        "#if you have any questions let me know\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgkzcWsrm3Jt",
        "outputId": "4c5058a5-2c7b-4736-c71e-b12d4a8a56c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "#the file downloading script does not work completely....so I downloaded\n",
        "#them manually and ran the script after downloading\n",
        "#import wget\n",
        "#url = \"http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T1.tar\"\n",
        "#t2 = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T2.tar'\n",
        "#pd = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-PD.tar'\n",
        "#mra = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-MRA.tar'\n",
        "#demographic = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls'\n",
        "\n",
        "#use an earlier version of tensorflow\n",
        "\n",
        "###use lines between -----------------\n",
        "#!pip uninstall tensorflow -y\n",
        "#!pip install \"tensorflow-gpu==1.4.0\"\n",
        "#%tensorflow_version 1.4\n",
        "\n",
        "#!git clone https://github.com/DLTK/DLTK.git \n",
        "\n",
        "#import tensorflow as tf\n",
        "#print(tf.__version__) # for both Python 2 and Python 3\n",
        "\n",
        "\n",
        "#get pretrained model \n",
        "!wget \"http://www.doc.ic.ac.uk/~mrajchl/dltk_models/examples/applications/IXI_HH_age_regression.tar.gz\"\n",
        "!tar -xvf '/content/IXI_HH_age_regression.tar.gz'\n",
        "\n",
        "\n",
        "## use  lines between ------------------\n",
        "\n",
        "#wget.download(t2, \"/Users/hernandezs4/Downloads/Jupyter\")\n",
        "#wget.download(pd, \"/Users/hernandezs4/Downloads/Jupyter\")\n",
        "#wget.download(mra, \"/Users/hernandezs4/Downloads/Jupyter\")\n",
        "#wget.download(demographic, \"/Users/hernandezs4/Downloads/Jupyter\")\n",
        "\n",
        "#changed \n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "--2020-10-11 20:44:54--  http://www.doc.ic.ac.uk/~mrajchl/dltk_models/examples/applications/IXI_HH_age_regression.tar.gz\n",
            "Resolving www.doc.ic.ac.uk (www.doc.ic.ac.uk)... 146.169.13.6\n",
            "Connecting to www.doc.ic.ac.uk (www.doc.ic.ac.uk)|146.169.13.6|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 146092814 (139M) [application/x-gzip]\n",
            "Saving to: ‘IXI_HH_age_regression.tar.gz.1’\n",
            "\n",
            "IXI_HH_age_regressi 100%[===================>] 139.32M  9.69MB/s    in 16s     \n",
            "\n",
            "2020-10-11 20:45:10 (8.90 MB/s) - ‘IXI_HH_age_regression.tar.gz.1’ saved [146092814/146092814]\n",
            "\n",
            "IXI_HH_age_regression/\n",
            "IXI_HH_age_regression/model.ckpt-50404.meta\n",
            "IXI_HH_age_regression/.nfs0000000003096d1000000002\n",
            "IXI_HH_age_regression/checkpoint\n",
            "IXI_HH_age_regression/graph.pbtxt\n",
            "IXI_HH_age_regression/model.ckpt-50404.index\n",
            "IXI_HH_age_regression/1510857419/\n",
            "IXI_HH_age_regression/1510857419/variables/\n",
            "IXI_HH_age_regression/1510857419/variables/variables.data-00000-of-00001\n",
            "IXI_HH_age_regression/1510857419/variables/variables.index\n",
            "IXI_HH_age_regression/1510857419/saved_model.pb\n",
            "IXI_HH_age_regression/model.ckpt-50404.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie8Jnahhm3Jz",
        "outputId": "64b902e5-acfd-4bcf-c506-40868007787f"
      },
      "source": [
        "#to download data \n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Download and extract the IXI Hammersmith Hospital 3T dataset\n",
        "url: http://brain-development.org/ixi-dataset/\n",
        "ref: IXI – Information eXtraction from Images (EPSRC GR/S21533/02)\n",
        "\"\"\"\n",
        "from __future__ import unicode_literals\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import\n",
        "from future.standard_library import install_aliases  # py 2/3 compatability\n",
        "install_aliases()\n",
        "\n",
        "from urllib.request import FancyURLopener\n",
        "\n",
        "import os.path\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import glob\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "\n",
        "DOWNLOAD_IMAGES = True\n",
        "EXTRACT_IMAGES = True\n",
        "PROCESS_OTHER = True\n",
        "RESAMPLE_IMAGES = True\n",
        "CLEAN_UP = True\n",
        "\n",
        "\n",
        "def resample_image(itk_image, out_spacing=(1.0, 1.0, 1.0), is_label=False):\n",
        "    original_spacing = itk_image.GetSpacing()\n",
        "    original_size = itk_image.GetSize()\n",
        "\n",
        "    out_size = [int(np.round(original_size[0] * (original_spacing[0] / out_spacing[0]))),\n",
        "                int(np.round(original_size[1] * (original_spacing[1] / out_spacing[1]))),\n",
        "                int(np.round(original_size[2] * (original_spacing[2] / out_spacing[2])))]\n",
        "\n",
        "    resample = sitk.ResampleImageFilter()\n",
        "    resample.SetOutputSpacing(out_spacing)\n",
        "    resample.SetSize(out_size)\n",
        "    resample.SetOutputDirection(itk_image.GetDirection())\n",
        "    resample.SetOutputOrigin(itk_image.GetOrigin())\n",
        "    resample.SetTransform(sitk.Transform())\n",
        "    resample.SetDefaultPixelValue(itk_image.GetPixelIDValue())\n",
        "\n",
        "    if is_label:\n",
        "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
        "    else:\n",
        "        resample.SetInterpolator(sitk.sitkBSpline)\n",
        "\n",
        "    return resample.Execute(itk_image)\n",
        "\n",
        "\n",
        "def reslice_image(itk_image, itk_ref, is_label=False):\n",
        "    resample = sitk.ResampleImageFilter()\n",
        "    resample.SetReferenceImage(itk_ref)\n",
        "\n",
        "    if is_label:\n",
        "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
        "    else:\n",
        "        resample.SetInterpolator(sitk.sitkBSpline)\n",
        "\n",
        "    return resample.Execute(itk_image)\n",
        "\n",
        "\n",
        "urls = {}\n",
        "urls['t1'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T1.tar'\n",
        "urls['t2'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T2.tar'\n",
        "urls['pd'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-PD.tar'\n",
        "urls['mra'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-MRA.tar'\n",
        "urls['demographic'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls'\n",
        "\n",
        "fnames = {}\n",
        "fnames['t1'] = 't1.tar'\n",
        "fnames['t2'] = 't2.tar'\n",
        "fnames['pd'] = 'pd.tar'\n",
        "fnames['mra'] = 'mra.tar'\n",
        "fnames['demographic'] = 'demographic.xls'\n",
        "\n",
        "\n",
        "if DOWNLOAD_IMAGES:\n",
        "    # Download all IXI data\n",
        "    for key, url in urls.items():\n",
        "\n",
        "        if not os.path.isfile(fnames[key]):\n",
        "            print('Downloading {} from {}'.format(fnames[key], url))\n",
        "            curr_file = FancyURLopener()\n",
        "            curr_file.retrieve(url, fnames[key])\n",
        "        else:\n",
        "            print('File {} already exists. Skipping download.'.format(\n",
        "                fnames[key]))\n",
        "\n",
        "if EXTRACT_IMAGES:\n",
        "    # Extract the HH subset of IXI\n",
        "    for key, fname in fnames.items():\n",
        "\n",
        "        if (fname.endswith('.tar')):\n",
        "            print('Extracting IXI HH data from {}.'.format(fnames[key]))\n",
        "            output_dir = os.path.join('./orig/', key)\n",
        "\n",
        "            if not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "\n",
        "            t = tarfile.open(fname, 'r')\n",
        "            for member in t.getmembers():\n",
        "                if '-HH-' in member.name:\n",
        "                    t.extract(member, output_dir)\n",
        "\n",
        "\n",
        "if PROCESS_OTHER:\n",
        "    # Process the demographic xls data and save to csv\n",
        "    xls = pd.ExcelFile('demographic.xls')\n",
        "    print(xls.sheet_names)\n",
        "\n",
        "    df = xls.parse('Table')\n",
        "    for index, row in df.iterrows():\n",
        "        IXI_id = 'IXI{:03d}'.format(row['IXI_ID'])\n",
        "        df.loc[index, 'IXI_ID'] = IXI_id\n",
        "\n",
        "        t1_exists = len(glob.glob('./orig/t1/{}*.nii.gz'.format(IXI_id)))\n",
        "        t2_exists = len(glob.glob('./orig/t2/{}*.nii.gz'.format(IXI_id)))\n",
        "        pd_exists = len(glob.glob('./orig/pd/{}*.nii.gz'.format(IXI_id)))\n",
        "        mra_exists = len(glob.glob('./orig/mra/{}*.nii.gz'.format(IXI_id)))\n",
        "\n",
        "        # Check if each entry is complete and drop if not\n",
        "        # if not t1_exists and not t2_exists and not pd_exists and not mra\n",
        "        # exists:\n",
        "        if not (t1_exists and t2_exists and pd_exists and mra_exists):\n",
        "            df.drop(index, inplace=True)\n",
        "\n",
        "    # Write to csv file\n",
        "    df.to_csv('demographic_HH.csv', index=False)\n",
        "\n",
        "if RESAMPLE_IMAGES:\n",
        "    # Resample the IXI HH T2 images to 1mm isotropic and reslice all\n",
        "    # others to it\n",
        "    #had to change to .to_numpy\n",
        "    df = pd.read_csv('demographic_HH.csv', dtype=object, keep_default_na=False,\n",
        "                     na_values=[]).to_numpy()\n",
        "\n",
        "    for i in df:\n",
        "        IXI_id = i[0]\n",
        "        print('Resampling {}'.format(IXI_id))\n",
        "\n",
        "        t1_fn = glob.glob('./orig/t1/{}*.nii.gz'.format(IXI_id))[0]\n",
        "        t2_fn = glob.glob('./orig/t2/{}*.nii.gz'.format(IXI_id))[0]\n",
        "        pd_fn = glob.glob('./orig/pd/{}*.nii.gz'.format(IXI_id))[0]\n",
        "        mra_fn = glob.glob('./orig/mra/{}*.nii.gz'.format(IXI_id))[0]\n",
        "\n",
        "        t1 = sitk.ReadImage(t1_fn)\n",
        "        t2 = sitk.ReadImage(t2_fn)\n",
        "        pd = sitk.ReadImage(pd_fn)\n",
        "        mra = sitk.ReadImage(mra_fn)\n",
        "\n",
        "        # Resample to 1mm isotropic resolution\n",
        "        t2_1mm = resample_image(t2)\n",
        "        t1_1mm = reslice_image(t1, t2_1mm)\n",
        "        pd_1mm = reslice_image(pd, t2_1mm)\n",
        "        mra_1mm = reslice_image(mra, t2_1mm)\n",
        "\n",
        "        output_dir = os.path.join('./1mm/', IXI_id)\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print('T1: {} {}'.format(t1_1mm.GetSize(), t1_1mm.GetSpacing()))\n",
        "        print('T2: {} {}'.format(t2_1mm.GetSize(), t2_1mm.GetSpacing()))\n",
        "        print('PD: {} {}'.format(pd_1mm.GetSize(), pd_1mm.GetSpacing()))\n",
        "        print('MRA: {} {}'.format(mra_1mm.GetSize(), mra_1mm.GetSpacing()))\n",
        "\n",
        "        sitk.WriteImage(t1_1mm, os.path.join(output_dir, 'T1_1mm.nii.gz'))\n",
        "        sitk.WriteImage(t2_1mm, os.path.join(output_dir, 'T2_1mm.nii.gz'))\n",
        "        sitk.WriteImage(pd_1mm, os.path.join(output_dir, 'PD_1mm.nii.gz'))\n",
        "        sitk.WriteImage(mra_1mm, os.path.join(output_dir, 'MRA_1mm.nii.gz'))\n",
        "\n",
        "        # Resample to 2mm isotropic resolution\n",
        "        t2_2mm = resample_image(t2, out_spacing=[2.0, 2.0, 2.0])\n",
        "        t1_2mm = reslice_image(t1, t2_2mm)\n",
        "        pd_2mm = reslice_image(pd, t2_2mm)\n",
        "        mra_2mm = reslice_image(mra, t2_2mm)\n",
        "\n",
        "        output_dir = os.path.join('./2mm/', IXI_id)\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print('T1: {} {}'.format(t2_2mm.GetSize(), t1_2mm.GetSpacing()))\n",
        "        print('T2: {} {}'.format(t2_2mm.GetSize(), t2_2mm.GetSpacing()))\n",
        "        print('PD: {} {}'.format(pd_2mm.GetSize(), pd_2mm.GetSpacing()))\n",
        "        print('MRA: {} {}'.format(mra_2mm.GetSize(), mra_2mm.GetSpacing()))\n",
        "\n",
        "        sitk.WriteImage(t1_2mm, os.path.join(output_dir, 'T1_2mm.nii.gz'))\n",
        "        sitk.WriteImage(t2_2mm, os.path.join(output_dir, 'T2_2mm.nii.gz'))\n",
        "        sitk.WriteImage(pd_2mm, os.path.join(output_dir, 'PD_2mm.nii.gz'))\n",
        "        sitk.WriteImage(mra_2mm, os.path.join(output_dir, 'MRA_2mm.nii.gz'))\n",
        "\n",
        "\n",
        "if CLEAN_UP:\n",
        "    # Remove the .tar files\n",
        "    for key, fname in fnames.items():\n",
        "        if (fname.endswith('.tar')):\n",
        "            os.remove(fname)\n",
        "\n",
        "    # Remove all data in original resolution\n",
        "    os.system('rm -rf orig')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File t1.tar already exists. Skipping download.\n",
            "File t2.tar already exists. Skipping download.\n",
            "File pd.tar already exists. Skipping download.\n",
            "File mra.tar already exists. Skipping download.\n",
            "File demographic.xls already exists. Skipping download.\n",
            "Extracting IXI HH data from t1.tar.\n",
            "Extracting IXI HH data from t2.tar.\n",
            "Extracting IXI HH data from pd.tar.\n",
            "Extracting IXI HH data from mra.tar.\n",
            "['Table', 'Ethnicity', 'Marital Status', 'Occupation', 'Qualification', 'Study Date']\n",
            "Resampling IXI012\n",
            "T1: (230, 230, 134) (1.0, 1.0, 1.0)\n",
            "T2: (230, 230, 134) (1.0, 1.0, 1.0)\n",
            "PD: (230, 230, 134) (1.0, 1.0, 1.0)\n",
            "MRA: (230, 230, 134) (1.0, 1.0, 1.0)\n",
            "T1: (115, 115, 67) (2.0, 2.0, 2.0)\n",
            "T2: (115, 115, 67) (2.0, 2.0, 2.0)\n",
            "PD: (115, 115, 67) (2.0, 2.0, 2.0)\n",
            "MRA: (115, 115, 67) (2.0, 2.0, 2.0)\n",
            "Resampling IXI013\n",
            "T1: (230, 230, 139) (1.0, 1.0, 1.0)\n",
            "T2: (230, 230, 139) (1.0, 1.0, 1.0)\n",
            "PD: (230, 230, 139) (1.0, 1.0, 1.0)\n",
            "MRA: (230, 230, 139) (1.0, 1.0, 1.0)\n",
            "T1: (115, 115, 70) (2.0, 2.0, 2.0)\n",
            "T2: (115, 115, 70) (2.0, 2.0, 2.0)\n",
            "PD: (115, 115, 70) (2.0, 2.0, 2.0)\n",
            "MRA: (115, 115, 70) (2.0, 2.0, 2.0)\n",
            "Resampling IXI015\n",
            "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "Resampling IXI033\n",
            "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "Resampling IXI034\n",
            "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "Resampling IXI039\n",
            "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
            "Resampling IXI048\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI049\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI051\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI052\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI056\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI057\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI059\n",
            "T1: (240, 240, 163) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 163) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 163) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 163) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI067\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI072\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI079\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI080\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI083\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI092\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI093\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI094\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI095\n",
            "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
            "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
            "Resampling IXI096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6ce04d40aac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mt2_1mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mt1_1mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreslice_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_1mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mpd_1mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreslice_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_1mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mmra_1mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreslice_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_1mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6ce04d40aac2>\u001b[0m in \u001b[0;36mreslice_image\u001b[0;34m(itk_image, itk_ref, is_label)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mresample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetInterpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msitkBSpline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitk_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.7/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36mExecute\u001b[0;34m(self, image1)\u001b[0m\n\u001b[1;32m  20323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  20324\u001b[0m         \u001b[0;34mr\"\"\"Execute(ResampleImageFilter self, Image image1) -> Image\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 20325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResampleImageFilter_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  20326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  20327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mSetReferenceImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1Mj-U7nm3J2"
      },
      "source": [
        "#training script to split dataset into training and validation set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uixK6E3um3Jw",
        "outputId": "030caea4-fda7-403a-ddb8-8704ce4c5210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#make custom reader script for dltk \n",
        "%%writefile reader.py\n",
        "\n",
        "\n",
        "from __future__ import unicode_literals\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import SimpleITK as sitk\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from dltk.io.augmentation import flip, extract_random_example_array\n",
        "from dltk.io.preprocessing import whitening\n",
        "\n",
        "\n",
        "def read_fn(file_references, mode, params=None):\n",
        "    \"\"\"A custom python read function for interfacing with nii image files.\n",
        "    Args:\n",
        "        file_references (list): A list of lists containing file references, such\n",
        "            as [['id_0', 'image_filename_0', target_value_0], ...,\n",
        "            ['id_N', 'image_filename_N', target_value_N]].\n",
        "        mode (str): One of the tf.estimator.ModeKeys strings: TRAIN, EVAL or\n",
        "            PREDICT.\n",
        "        params (dict, optional): A dictionary to parametrise read_fn ouputs\n",
        "            (e.g. reader_params = {'n_examples': 10, 'example_size':\n",
        "            [64, 64, 64], 'extract_examples': True}, etc.).\n",
        "    Yields:\n",
        "        dict: A dictionary of reader outputs for dltk.io.abstract_reader.\n",
        "    \"\"\"\n",
        "\n",
        "    def _augment(img):\n",
        "        \"\"\"An image augmentation function\"\"\"\n",
        "        return flip(img, axis=2)\n",
        "\n",
        "    for f in file_references:\n",
        "        subject_id = f[0]\n",
        "\n",
        "        data_path = '/content/IXI_HH_age_regression'\n",
        "\n",
        "        # Read the image nii with sitk\n",
        "        t1_fn = os.path.join(data_path, '{}/T1_2mm.nii.gz'.format(subject_id))\n",
        "        t1 = sitk.GetArrayFromImage(sitk.ReadImage(str(t1_fn)))\n",
        "\n",
        "        # Normalise volume image\n",
        "        t1 = whitening(t1)\n",
        "\n",
        "        # Create a 4D image (i.e. [x, y, z, channels])\n",
        "        images = np.expand_dims(t1, axis=-1).astype(np.float32)\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            yield {'features': {'x': images}, 'img_id': subject_id}\n",
        "\n",
        "        # Parse the regression targets from the file_references\n",
        "        age = np.float(f[11])\n",
        "        y = np.expand_dims(age, axis=-1).astype(np.float32)\n",
        "\n",
        "        # Augment if used in training mode\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            images = _augment(images)\n",
        "\n",
        "        # Check if the reader is supposed to return training examples or full\n",
        "        #  images\n",
        "        if params['extract_examples']:\n",
        "            images = extract_random_example_array(\n",
        "                image_list=images,\n",
        "                example_size=params['example_size'],\n",
        "                n_examples=params['n_examples'])\n",
        "\n",
        "            for e in range(params['n_examples']):\n",
        "                yield {'features': {'x': images[e].astype(np.float32)},\n",
        "                       'labels': {'y': y.astype(np.float32)},\n",
        "                       'img_id': subject_id}\n",
        "\n",
        "        else:\n",
        "            yield {'features': {'x': images},\n",
        "                   'labels': {'y': y.astype(np.float32)},\n",
        "                   'img_id': subject_id}\n",
        "\n",
        "    return\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting reader.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB0WKTn9EDqN",
        "outputId": "13697eda-1d8c-4cc1-fc9c-859a24574463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#had to adjust the abstract_reader.py\n",
        "%%writefile sh_abstract_reader.py\n",
        "\n",
        "from __future__ import unicode_literals\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import tensorflow as tf\n",
        "import traceback\n",
        "\n",
        "#changed this line to tf.compat.v1.train.SessionRunHook\n",
        "class IteratorInitializerHook(tf.compat.v1.train.SessionRunHook):\n",
        "    \"\"\"Hook to initialise data iterator after Session is created.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(IteratorInitializerHook, self).__init__()\n",
        "        self.iterator_initializer_func = None\n",
        "\n",
        "    def after_create_session(self, session, coord):\n",
        "        \"\"\"Initialise the iterator after the session has been created.\"\"\"\n",
        "        self.iterator_initializer_func(session)\n",
        "\n",
        "\n",
        "class Reader(object):\n",
        "    \"\"\"Wrapper for dataset generation given a read function\"\"\"\n",
        "\n",
        "    def __init__(self, read_fn, dtypes):\n",
        "        \"\"\"Constructs a Reader instance\n",
        "        Args:\n",
        "            read_fn: Input function returning features which is a dictionary of\n",
        "                string feature name to `Tensor` or `SparseTensor`. If it\n",
        "                returns a tuple, first item is extracted as features.\n",
        "                Prediction continues until `input_fn` raises an end-of-input\n",
        "                exception (`OutOfRangeError` or `StopIteration`).\n",
        "            dtypes:  A nested structure of tf.DType objects corresponding to\n",
        "                each component of an element yielded by generator.\n",
        "        \"\"\"\n",
        "        self.dtypes = dtypes\n",
        "\n",
        "        self.read_fn = read_fn\n",
        "\n",
        "    def get_inputs(self,\n",
        "                   file_references,\n",
        "                   mode,\n",
        "                   example_shapes=None,\n",
        "                   shuffle_cache_size=100,\n",
        "                   batch_size=4,\n",
        "                   params=None):\n",
        "        \"\"\"\n",
        "        Function to provide the input_fn for a tf.Estimator.\n",
        "        Args:\n",
        "            file_references: An array like structure that holds the reference\n",
        "                to the file to read. It can also be None if not needed.\n",
        "            mode: A tf.estimator.ModeKeys. It is passed on to `read_fn` to\n",
        "                trigger specific functions there.\n",
        "            example_shapes (optional): A nested structure of lists or tuples\n",
        "                corresponding to the shape of each component of an element\n",
        "                yielded by generator.\n",
        "            shuffle_cache_size (int, optional): An `int` determining the\n",
        "                number of examples that are held in the shuffle queue.\n",
        "            batch_size (int, optional): An `int` specifying the number of\n",
        "                examples returned in a batch.\n",
        "            params (dict, optional): A `dict` passed on to the `read_fn`.\n",
        "        Returns:\n",
        "            function: a handle to the `input_fn` to be passed the relevant\n",
        "                tf estimator functions.\n",
        "            tf.train.SessionRunHook: A hook to initialize the queue within\n",
        "                the dataset.\n",
        "        \"\"\"\n",
        "        iterator_initializer_hook = IteratorInitializerHook()\n",
        "\n",
        "        def train_inputs():\n",
        "            def f():\n",
        "                def clean_ex(ex, compare):\n",
        "                    # Clean example dictionary by recursively deleting\n",
        "                    # non-relevant entries. However, this does not look into\n",
        "                    # dictionaries nested into lists\n",
        "                    for k in list(ex.keys()):\n",
        "                        if k not in list(compare.keys()):\n",
        "                            del ex[k]\n",
        "                        elif isinstance(ex[k], dict) and isinstance(compare[k], dict):\n",
        "                            clean_ex(ex[k], compare[k])\n",
        "                        elif (isinstance(ex[k], dict) and not isinstance(compare[k], dict)) or \\\n",
        "                             (not isinstance(ex[k], dict) and isinstance(compare[k], dict)):\n",
        "                            raise ValueError('Entries between example and '\n",
        "                                             'dtypes incompatible for key {}'\n",
        "                                             ''.format(k))\n",
        "                        elif (isinstance(ex[k], list) and not isinstance(compare[k], list)) or \\\n",
        "                            (not isinstance(ex[k], list) and isinstance(compare[k], list)) or \\\n",
        "                                (isinstance(ex[k], list) and isinstance(compare[k], list) and not\n",
        "                                    len(ex[k]) == len(compare[k])):\n",
        "                            raise ValueError('Entries between example and '\n",
        "                                             'dtypes incompatible for key {}'\n",
        "                                             ''.format(k))\n",
        "                    for k in list(compare):\n",
        "                        if k not in list(ex.keys()):\n",
        "                            raise ValueError('Key {} not found in ex but is '\n",
        "                                             'present in dtypes. Found keys: '\n",
        "                                             '{}'.format(k, ex.keys()))\n",
        "                    return ex\n",
        "\n",
        "                fn = self.read_fn(file_references, mode, params)\n",
        "                # iterate over all entries - this loop is terminated by the\n",
        "                # tf.errors.OutOfRangeError or StopIteration thrown by the\n",
        "                # read_fn\n",
        "                while True:\n",
        "                    try:\n",
        "                        ex = next(fn)\n",
        "\n",
        "                        if ex.get('labels') is None:\n",
        "                            ex['labels'] = None\n",
        "\n",
        "                        if not isinstance(ex, dict):\n",
        "                            raise ValueError('The read_fn has to return '\n",
        "                                             'dictionaries')\n",
        "\n",
        "                        ex = clean_ex(ex, self.dtypes)\n",
        "                        yield ex\n",
        "                    except (tf.errors.OutOfRangeError, StopIteration):\n",
        "                        raise\n",
        "                    except Exception as e:\n",
        "                        print('got error `{} from `_read_sample`:'.format(e))\n",
        "                        print(traceback.format_exc())\n",
        "                        raise\n",
        "\n",
        "            dataset = tf.data.Dataset.from_generator(\n",
        "                f, self.dtypes, example_shapes)\n",
        "            dataset = dataset.repeat(None)\n",
        "            dataset = dataset.shuffle(shuffle_cache_size)\n",
        "            dataset = dataset.batch(batch_size)\n",
        "            dataset = dataset.prefetch(1)\n",
        "\n",
        "            iterator = dataset.make_initializable_iterator()\n",
        "            next_dict = iterator.get_next()\n",
        "\n",
        "            # Set runhook to initialize iterator\n",
        "            iterator_initializer_hook.iterator_initializer_func = \\\n",
        "                lambda sess: sess.run(iterator.initializer)\n",
        "\n",
        "            # Return batched (features, labels)\n",
        "            return next_dict['features'], next_dict.get('labels')\n",
        "\n",
        "        # Return function and hook\n",
        "        return train_inputs, iterator_initializer_hook\n",
        "\n",
        "    def serving_input_receiver_fn(self, placeholder_shapes):\n",
        "        \"\"\"Build the serving inputs.\n",
        "        Args:\n",
        "            placeholder_shapes: A nested structure of lists or tuples\n",
        "                corresponding to the shape of each component of the feature\n",
        "                elements yieled by the read_fn.\n",
        "        Returns:\n",
        "            function: A function to be passed to the tf.estimator.Estimator\n",
        "            instance when exporting a saved model with estimator.export_savedmodel.\n",
        "        \"\"\"\n",
        "\n",
        "        def f():\n",
        "            inputs = {k: tf.placeholder(\n",
        "                shape=[None] + list(placeholder_shapes['features'][k]),\n",
        "                dtype=self.dtypes['features'][k]) for k in list(self.dtypes['features'].keys())}\n",
        "\n",
        "            return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
        "        return f\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing sh_abstract_reader.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9-ws7wtG7MY"
      },
      "source": [
        "#had to edit the train.py script since it needed to access my edited version of \n",
        "#sh_abstract_reader.py\n"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Se5p4vEm3J5"
      },
      "source": [
        "#here I tried to load the provided python scripts and edited scripts as modules\n",
        "#!pip install dltk\n",
        "import dltk  \n",
        "\n",
        "#!git clone https://github.com/DLTK/DLTK.git\n",
        "#for some reason the custom scripts even from dltk have to be in /content/\n",
        "\n",
        "sh_abstract_reader_path = '/content/sh_abstract_reader.py'\n",
        "path_to_read = \"/content/reader.py\"\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/sh_abstract_reader.py')\n",
        "sys.path.append(os.path.abspath(path_to_read))\n",
        "import sh_abstract_reader\n",
        "#from sh_abstract_reader import Reader\n",
        "import reader\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfFomFCDm3J8",
        "outputId": "36223aff-f9ee-45bc-b28f-415bd4adaad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#edited version of train.py\n",
        "#will output to a file named sh_train.py\n",
        "%%writefile sh_train.py\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import unicode_literals\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "#.compat.v1\n",
        "#tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "from dltk.networks.regression_classification.resnet import resnet_3d\n",
        "from sh_abstract_reader import Reader\n",
        "\n",
        "import reader \n",
        "\n",
        "EVAL_EVERY_N_STEPS = 100\n",
        "EVAL_STEPS = 5\n",
        "\n",
        "NUM_CLASSES = 1\n",
        "NUM_CHANNELS = 1\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "SHUFFLE_CACHE_SIZE = 32\n",
        "\n",
        "MAX_STEPS = 50000\n",
        "\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    \"\"\"Model function to construct a tf.estimator.EstimatorSpec. It creates a\n",
        "        network given input features (e.g. from a dltk.io.abstract_reader) and\n",
        "        training targets (labels). Further, loss, optimiser, evaluation ops and\n",
        "        custom tensorboard summary ops can be added. For additional information,\n",
        "        please refer to\n",
        "        https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#model_fn.\n",
        "    Args:\n",
        "        features (tf.Tensor): Tensor of input features to train from. Required\n",
        "            rank and dimensions are determined by the subsequent ops (i.e.\n",
        "            the network).\n",
        "        labels (tf.Tensor): Tensor of training targets or labels. Required rank\n",
        "            and dimensions are determined by the network output.\n",
        "        mode (str): One of the tf.estimator.ModeKeys: TRAIN, EVAL or PREDICT\n",
        "        params (dict, optional): A dictionary to parameterise the model_fn\n",
        "            (e.g. learning_rate)\n",
        "    Returns:\n",
        "        tf.estimator.EstimatorSpec: A custom EstimatorSpec for this experiment\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. create a model and its outputs\n",
        "    net_output_ops = resnet_3d(\n",
        "        inputs=features['x'],\n",
        "        num_res_units=2,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        filters=(16, 32, 64, 128, 256),\n",
        "        strides=((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)),\n",
        "        mode=mode,\n",
        "        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-4))\n",
        "\n",
        "    # 1.1 Generate predictions only (for `ModeKeys.PREDICT`)\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode=mode,\n",
        "            predictions=net_output_ops,\n",
        "            export_outputs={'out': tf.estimator.export.PredictOutput(net_output_ops)})\n",
        "\n",
        "    # 2. set up a loss function\n",
        "    loss = tf.losses.mean_squared_error(\n",
        "        labels=labels['y'],\n",
        "        predictions=net_output_ops['logits'])\n",
        "\n",
        "    # 3. define a training op and ops for updating moving averages (i.e.\n",
        "    # for batch normalisation)\n",
        "    global_step = tf.train.get_global_step()\n",
        "    optimiser = tf.train.AdamOptimizer(learning_rate = params[\"learning_rate\"],\n",
        "        epsilon=1e-5)\n",
        "\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        train_op = optimiser.minimize(loss, global_step=global_step)\n",
        "\n",
        "    # 4.1 (optional) create custom image summaries for tensorboard\n",
        "    my_image_summaries = {}\n",
        "    my_image_summaries['feat_t1'] = features['x'][0, 32, :, :, 0]\n",
        "\n",
        "    expected_output_size = [1, 96, 96, 1]  # [B, W, H, C]\n",
        "    [tf.summary.image(name, tf.reshape(image, expected_output_size))\n",
        "     for name, image in my_image_summaries.items()]\n",
        "\n",
        "    # 4.2 (optional) track the rmse (scaled back by 100, see reader.py)\n",
        "    rmse = tf.metrics.root_mean_squared_error\n",
        "    mae = tf.metrics.mean_absolute_error\n",
        "    eval_metric_ops = {\"rmse\": rmse(labels['y'], net_output_ops['logits']),\n",
        "                       \"mae\": mae(labels['y'], net_output_ops['logits'])}\n",
        "\n",
        "    # 5. Return EstimatorSpec object\n",
        "    return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                      predictions=net_output_ops,\n",
        "                                      loss=loss,\n",
        "                                      train_op=train_op,\n",
        "                                      eval_metric_ops=eval_metric_ops)\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    np.random.seed(42)\n",
        "    tf.set_random_seed(42)\n",
        "\n",
        "    print('Setting up...')\n",
        "\n",
        "    # Parse csv files for file names\n",
        "    all_filenames = pd.read_csv(\n",
        "        args.data_csv,\n",
        "        dtype=object,\n",
        "        keep_default_na=False,\n",
        "        na_values=[]).to_numpy()\n",
        "\n",
        "    train_filenames = all_filenames[:150]\n",
        "    val_filenames = all_filenames[150:]\n",
        "\n",
        "    # Set up a data reader to handle the file i/o.\n",
        "    reader_params = {'n_examples': 2,\n",
        "                     'example_size': [64, 96, 96],\n",
        "                     'extract_examples': True}\n",
        "\n",
        "    reader_example_shapes = {'features': {'x': reader_params['example_size'] + [NUM_CHANNELS, ]},\n",
        "                             'labels': {'y': [1]}}\n",
        "\n",
        "    fixed = Reader(reader.read_fn, {'features': {'x': tf.float32},\n",
        "                              'labels': {'y': tf.float32}})\n",
        "\n",
        "    # Get input functions and queue initialisation hooks for training and\n",
        "    # validation data\n",
        "\n",
        "    train_input_fn, train_qinit_hook = fixed.get_inputs(\n",
        "        file_references=train_filenames,\n",
        "        mode=tf.estimator.ModeKeys.TRAIN,\n",
        "        example_shapes=reader_example_shapes,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle_cache_size=SHUFFLE_CACHE_SIZE,\n",
        "        params=reader_params)\n",
        "\n",
        "    val_input_fn, val_qinit_hook = fixed.get_inputs(\n",
        "        file_references=val_filenames,\n",
        "        mode=tf.estimator.ModeKeys.EVAL,\n",
        "        example_shapes=reader_example_shapes,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle_cache_size=SHUFFLE_CACHE_SIZE,\n",
        "        params=reader_params)\n",
        "\n",
        "    # Instantiate the neural network estimator\n",
        "    nn = tf.estimator.Estimator(\n",
        "        model_fn=model_fn,\n",
        "        model_dir=args.model_path,\n",
        "        params={\"learning_rate\": 0.001},\n",
        "        config=tf.estimator.RunConfig())\n",
        "\n",
        "    # Hooks for validation summaries\n",
        "    val_summary_hook = tf.contrib.training.SummaryAtEndHook(\n",
        "        os.path.join(args.model_path, 'eval'))\n",
        "    step_cnt_hook = tf.train.StepCounterHook(\n",
        "        every_n_steps=EVAL_EVERY_N_STEPS, output_dir=args.model_path)\n",
        "\n",
        "    print('Starting training...')\n",
        "    try:\n",
        "        for _ in range(MAX_STEPS // EVAL_EVERY_N_STEPS):\n",
        "            nn.train(input_fn=train_input_fn,\n",
        "                     hooks=[train_qinit_hook, step_cnt_hook],\n",
        "                     steps=EVAL_EVERY_N_STEPS)\n",
        "\n",
        "            if args.run_validation:\n",
        "                results_val = nn.evaluate(input_fn=val_input_fn,\n",
        "                                          hooks=[val_qinit_hook, val_summary_hook],\n",
        "                                          steps=EVAL_STEPS)\n",
        "                print('Step = {}; val loss = {:.5f};'.format(\n",
        "                    results_val['global_step'],\n",
        "                    results_val['loss']))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    print('Stopping now.')\n",
        "\n",
        "    # When exporting we set the expected input shape to be arbitrary.\n",
        "    export_dir = nn.export_savedmodel(\n",
        "        export_dir_base=args.model_path,\n",
        "        serving_input_receiver_fn=reader.serving_input_receiver_fn(\n",
        "            {'features': {'x': [None, None, None, NUM_CHANNELS]},\n",
        "             'labels': {'y': [1]}}))\n",
        "    print('Model saved to {}.'.format(export_dir))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set up argument parser\n",
        "    parser = argparse.ArgumentParser(description='Example: IXI HH resnet age regression training script')\n",
        "    parser.add_argument('--run_validation', default=True)\n",
        "    parser.add_argument('--restart', default=False, action='store_true')\n",
        "    parser.add_argument('--verbose', default=False, action='store_true')\n",
        "    parser.add_argument('--cuda_devices', '-c', default='0')\n",
        "\n",
        "    parser.add_argument('--model_path', '-p', default='/tmp/IXI_age_regression/')\n",
        "    parser.add_argument('--data_csv', default='../../../data/IXI_HH/demographic_HH.csv')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Set verbosity\n",
        "    if args.verbose:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "        tf.logging.set_verbosity(tf.logging.INFO)\n",
        "    else:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "    # GPU allocation options\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_devices\n",
        "\n",
        "    # Handle restarting and resuming training\n",
        "    if args.restart:\n",
        "        print('Restarting training from scratch.')\n",
        "        os.system('rm -rf {}'.format(args.model_path))\n",
        "\n",
        "    if not os.path.isdir(args.model_path):\n",
        "        os.system('mkdir -p {}'.format(args.model_path))\n",
        "    else:\n",
        "        print('Resuming training on model_path {}'.format(args.model_path))\n",
        "\n",
        "    # Call training\n",
        "    train(args)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing sh_train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldwxyfC1W78Q",
        "outputId": "c6abb406-5e7d-4439-adf8-8b6a7aa551a9",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "#running the training script\n",
        "\n",
        "#extract files from pretrained model\n",
        "#!gzip -d '/content/IXI_HH_age_regression.tar.gz'\n",
        "#!tar -xvf /content/IXI_HH_age_regression.tar\n",
        "\n",
        "#assign path to pretrained model\n",
        "\n",
        "#the issues I am running into may be because the tensorflow version used to \n",
        "#create the scripts is older than the current tensorflow version I am using...\n",
        "\n",
        "#to upload local files to collab\n",
        "#need to upload the demographic.csv file\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "\n",
        "!python /content/sh_train.py --model_path '/content/IXI_HH_age_regression'  --data_csv /content/demographic_HH.csv"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c0f04b1-cb90-47ad-a4b4-6a201b881831\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c0f04b1-cb90-47ad-a4b4-6a201b881831\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving demographic_HH.csv to demographic_HH.csv\n",
            "2020-10-11 20:12:20.496255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sh_train.py\", line 214, in <module>\n",
            "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
            "AttributeError: module 'tensorflow' has no attribute 'logging'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr2xLOA2m3J-",
        "outputId": "41798e84-3c32-4ee8-a1be-efcb09e7e301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#now that the model is trained \n",
        "#deploy aka output the results\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object `tensorflow_hub` not found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj07L8COR8hi"
      },
      "source": [
        "#since tensorflow.contrib is no longer available i found the source code and will import the functions from there\n",
        "path_to_predictor = \"/content/predictor.py\"\n",
        "path_to_core_estimator_predictor = \"/content/core_estimator_predictor.py\"\n",
        "path_to_contrib_estimator_predictor = \"/content/contrib_estimator_predictor.py\"\n",
        "path_to_predictor_factories = \"/content/predictor_factories.py\"\n",
        "path_to_saved_model_predictor = \"/content/saved_model_predictor.py\"\n",
        "path_to_contrib_reader = \"/content/contrib_reader.py\"\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(path_to_predictor))\n",
        "sys.path.append(os.path.abspath(path_to_core_estimator_predictor))\n",
        "sys.path.append(os.path.abspath(path_to_contrib_estimator_predictor))\n",
        "sys.path.append(os.path.abspath(path_to_predictor_factories))\n",
        "sys.path.append(os.path.abspath(path_to_saved_model_predictor))\n",
        "sys.path.append(os.path.abspath(path_to_contrib_reader))\n",
        "\n",
        "\n",
        "import predictor\n",
        "import predictor_factories\n",
        "import core_estimator_predictor\n",
        "import contrib_estimator_predictor\n",
        "import saved_model_predictor\n",
        "import contrib_reader\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2T-DVe5TEAV",
        "outputId": "d25be3ab-548c-4ba3-f0d0-420917f3f2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile predictor_factories.py\n",
        "\n",
        "\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Factory functions for `Predictor`s.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import contrib_estimator_predictor\n",
        "import core_estimator_predictor\n",
        "import saved_model_predictor\n",
        "\n",
        "#from tensorflow.contrib.learn.python.learn.estimators import estimator as contrib_estimator\n",
        "\n",
        "from tensorflow.python.estimator import estimator as core_estimator\n",
        "\n",
        "\n",
        "def from_contrib_estimator(estimator,\n",
        "                           prediction_input_fn,\n",
        "                           input_alternative_key=None,\n",
        "                           output_alternative_key=None,\n",
        "                           graph=None,\n",
        "                           config=None):\n",
        "  \"\"\"Constructs a `Predictor` from a `tf.contrib.learn.Estimator`.\n",
        "  Args:\n",
        "    estimator: an instance of `tf.contrib.learn.Estimator`.\n",
        "    prediction_input_fn: a function that takes no arguments and returns an\n",
        "      instance of `InputFnOps`.\n",
        "    input_alternative_key: Optional. Specify the input alternative used for\n",
        "      prediction.\n",
        "    output_alternative_key: Specify the output alternative used for\n",
        "      prediction. Not needed for single-headed models but required for\n",
        "      multi-headed models.\n",
        "    graph: Optional. The Tensorflow `graph` in which prediction should be\n",
        "      done.\n",
        "    config: `ConfigProto` proto used to configure the session.\n",
        "  Returns:\n",
        "    An initialized `Predictor`.\n",
        "  Raises:\n",
        "    TypeError: if `estimator` is a core `Estimator` instead of a contrib\n",
        "      `Estimator`.\n",
        "  \"\"\"\n",
        "  if isinstance(estimator, core_estimator.Estimator):\n",
        "    raise TypeError('Expected estimator to be of type '\n",
        "                    'tf.contrib.learn.Estimator, but got type '\n",
        "                    'tf.python.estimator.Estimator. You likely want to call '\n",
        "                    'from_estimator.')\n",
        "  return contrib_estimator_predictor.ContribEstimatorPredictor(\n",
        "      estimator,\n",
        "      prediction_input_fn,\n",
        "      input_alternative_key=input_alternative_key,\n",
        "      output_alternative_key=output_alternative_key,\n",
        "      graph=graph,\n",
        "      config=config)\n",
        "\n",
        "\n",
        "def from_estimator(estimator,\n",
        "                   serving_input_receiver_fn,\n",
        "                   output_key=None,\n",
        "                   graph=None,\n",
        "                   config=None):\n",
        "  \"\"\"Constructs a `Predictor` from a `tf.python.estimator.Estimator`.\n",
        "  Args:\n",
        "    estimator: an instance of `learn.python.estimator.Estimator`.\n",
        "    serving_input_receiver_fn: a function that takes no arguments and returns\n",
        "      an instance of `ServingInputReceiver` compatible with `estimator`.\n",
        "    output_key: Optional string specifying the export output to use. If\n",
        "      `None`, then `DEFAULT_SERVING_SIGNATURE_DEF_KEY` is used.\n",
        "    graph: Optional. The Tensorflow `graph` in which prediction should be\n",
        "      done.\n",
        "    config: `ConfigProto` proto used to configure the session.\n",
        "  Returns:\n",
        "    An initialized `Predictor`.\n",
        "  Raises:\n",
        "    TypeError: if `estimator` is a contrib `Estimator` instead of a core\n",
        "      `Estimator`.\n",
        "  \"\"\"\n",
        "  if isinstance(estimator, contrib_estimator.Estimator):\n",
        "    raise TypeError('Expected estimator to be of type '\n",
        "                    'tf.python.estimator.Estimator, but got type '\n",
        "                    'tf.contrib.learn.Estimator. You likely want to call '\n",
        "                    'from_contrib_estimator.')\n",
        "  return core_estimator_predictor.CoreEstimatorPredictor(\n",
        "      estimator,\n",
        "      serving_input_receiver_fn,\n",
        "      output_key=output_key,\n",
        "      graph=graph,\n",
        "      config=config)\n",
        "\n",
        "\n",
        "def from_saved_model(export_dir,\n",
        "                     signature_def_key=None,\n",
        "                     signature_def=None,\n",
        "                     input_names=None,\n",
        "                     output_names=None,\n",
        "                     tags=None,\n",
        "                     graph=None,\n",
        "                     config=None):\n",
        "  \"\"\"Constructs a `Predictor` from a `SavedModel` on disk.\n",
        "  Args:\n",
        "    export_dir: a path to a directory containing a `SavedModel`.\n",
        "    signature_def_key: Optional string specifying the signature to use. If\n",
        "      `None`, then `DEFAULT_SERVING_SIGNATURE_DEF_KEY` is used. Only one of\n",
        "    `signature_def_key` and `signature_def`\n",
        "    signature_def: A `SignatureDef` proto specifying the inputs and outputs\n",
        "      for prediction. Only one of `signature_def_key` and `signature_def`\n",
        "      should be specified.\n",
        "      input_names: A dictionary mapping strings to `Tensor`s in the `SavedModel`\n",
        "        that represent the input. The keys can be any string of the user's\n",
        "        choosing.\n",
        "      output_names: A dictionary mapping strings to `Tensor`s in the\n",
        "        `SavedModel` that represent the output. The keys can be any string of\n",
        "        the user's choosing.\n",
        "    tags: Optional. Tags that will be used to retrieve the correct\n",
        "      `SignatureDef`. Defaults to `DEFAULT_TAGS`.\n",
        "    graph: Optional. The Tensorflow `graph` in which prediction should be\n",
        "      done.\n",
        "    config: `ConfigProto` proto used to configure the session.\n",
        "  Returns:\n",
        "    An initialized `Predictor`.\n",
        "  Raises:\n",
        "    ValueError: More than one of `signature_def_key` and `signature_def` is\n",
        "      specified.\n",
        "  \"\"\"\n",
        "  return saved_model_predictor.SavedModelPredictor(\n",
        "      export_dir,\n",
        "      signature_def_key=signature_def_key,\n",
        "      signature_def=signature_def,\n",
        "      input_names=input_names,\n",
        "      output_names=output_names,\n",
        "      tags=tags,\n",
        "      graph=graph,\n",
        "      config=config)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting predictor_factories.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQvMYJyIT4l-",
        "outputId": "e53dfcaf-c190-4619-bfa8-1cb76e7f3868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile predictor.py\n",
        "\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Abstract base class for all predictors.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import six\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class Predictor(object):\n",
        "  \"\"\"Abstract base class for all predictors.\"\"\"\n",
        "\n",
        "  @property\n",
        "  def graph(self):\n",
        "    return self._graph\n",
        "\n",
        "  @property\n",
        "  def session(self):\n",
        "    return self._session\n",
        "\n",
        "  @property\n",
        "  def feed_tensors(self):\n",
        "    return self._feed_tensors\n",
        "\n",
        "  @property\n",
        "  def fetch_tensors(self):\n",
        "    return self._fetch_tensors\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '{} with feed tensors {} and fetch_tensors {}'.format(\n",
        "        type(self).__name__, self._feed_tensors, self._fetch_tensors)\n",
        "\n",
        "  def __call__(self, input_dict):\n",
        "    \"\"\"Returns predictions based on `input_dict`.\n",
        "    Args:\n",
        "      input_dict: a `dict` mapping strings to numpy arrays. These keys\n",
        "        must match `self._feed_tensors.keys()`.\n",
        "    Returns:\n",
        "      A `dict` mapping strings to numpy arrays. The keys match\n",
        "      `self.fetch_tensors.keys()`.\n",
        "    Raises:\n",
        "      ValueError: `input_dict` does not match `feed_tensors`.\n",
        "    \"\"\"\n",
        "    # TODO(jamieas): make validation optional?\n",
        "    input_keys = set(input_dict.keys())\n",
        "    expected_keys = set(self.feed_tensors.keys())\n",
        "    unexpected_keys = input_keys - expected_keys\n",
        "    if unexpected_keys:\n",
        "      raise ValueError(\n",
        "          'Got unexpected keys in input_dict: {}\\nexpected: {}'.format(\n",
        "              unexpected_keys, expected_keys))\n",
        "\n",
        "    feed_dict = {}\n",
        "    for key in self.feed_tensors.keys():\n",
        "      value = input_dict.get(key)\n",
        "      if value is not None:\n",
        "        feed_dict[self.feed_tensors[key]] = value\n",
        "    return self._session.run(fetches=self.fetch_tensors, feed_dict=feed_dict)\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting predictor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdD_XVlVUwW2",
        "outputId": "1f9e251e-bf08-43df-b1fb-d157d46cab76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#make contrib_estimator_predictor script\n",
        "\n",
        "%%writefile contrib_estimator_predictor.py\n",
        "\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"A `Predictor constructed from a `tf.contrib.learn.Estimator`.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "#from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\n",
        "import predictor_factories\n",
        "import predictor\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.training import checkpoint_management\n",
        "from tensorflow.python.training import monitored_session\n",
        "\n",
        "\n",
        "class ContribEstimatorPredictor(predictor.Predictor):\n",
        "  \"\"\"A `Predictor constructed from a `tf.contrib.learn.Estimator`.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               estimator,\n",
        "               prediction_input_fn,\n",
        "               input_alternative_key=None,\n",
        "               output_alternative_key=None,\n",
        "               graph=None,\n",
        "               config=None):\n",
        "    \"\"\"Initialize a `ContribEstimatorPredictor`.\n",
        "    Args:\n",
        "      estimator: an instance of `tf.contrib.learn.Estimator`.\n",
        "      prediction_input_fn: a function that takes no arguments and returns an\n",
        "        instance of `InputFnOps`.\n",
        "      input_alternative_key: Optional. Specify the input alternative used for\n",
        "        prediction.\n",
        "      output_alternative_key: Specify the output alternative used for\n",
        "        prediction. Not needed for single-headed models but required for\n",
        "        multi-headed models.\n",
        "      graph: Optional. The Tensorflow `graph` in which prediction should be\n",
        "        done.\n",
        "      config: `ConfigProto` proto used to configure the session.\n",
        "    \"\"\"\n",
        "    self._graph = graph or ops.Graph()\n",
        "    with self._graph.as_default():\n",
        "      input_fn_ops = prediction_input_fn()\n",
        "      # pylint: disable=protected-access\n",
        "      model_fn_ops = estimator._get_predict_ops(input_fn_ops.features)\n",
        "      # pylint: enable=protected-access\n",
        "      checkpoint_path = checkpoint_management.latest_checkpoint(\n",
        "          estimator.model_dir)\n",
        "      self._session = monitored_session.MonitoredSession(\n",
        "          session_creator=monitored_session.ChiefSessionCreator(\n",
        "              config=config,\n",
        "              checkpoint_filename_with_path=checkpoint_path))\n",
        "\n",
        "    input_alternative_key = (\n",
        "        input_alternative_key or\n",
        "        saved_model_export_utils.DEFAULT_INPUT_ALTERNATIVE_KEY)\n",
        "    input_alternatives, _ = saved_model_export_utils.get_input_alternatives(\n",
        "        input_fn_ops)\n",
        "    self._feed_tensors = input_alternatives[input_alternative_key]\n",
        "\n",
        "    (output_alternatives,\n",
        "     output_alternative_key) = saved_model_export_utils.get_output_alternatives(\n",
        "         model_fn_ops, output_alternative_key)\n",
        "    _, fetch_tensors = output_alternatives[output_alternative_key]\n",
        "    self._fetch_tensors = fetch_tensors\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting contrib_estimator_predictor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upYdkGSzU_Cq",
        "outputId": "38eec564-3d5f-4845-d895-4f93f2b6253c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#make core_estimator_predictor\n",
        "%%writefile core_estimator_predictor.py\n",
        "\n",
        "\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"A `Predictor` constructed from an `learn.python.estimator.Estimator`.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import predictor_factories\n",
        "import predictor\n",
        "from tensorflow.python.estimator import model_fn\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.saved_model import signature_constants\n",
        "from tensorflow.python.training import monitored_session\n",
        "\n",
        "\n",
        "def _get_signature_def(\n",
        "    serving_input_receiver, estimator, output_key=None):\n",
        "  \"\"\"Construct a `SignatureDef` proto.\"\"\"\n",
        "  if output_key is None:\n",
        "    output_key = signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
        "  # pylint: disable=protected-access\n",
        "  estimator_spec = estimator.model_fn(\n",
        "      serving_input_receiver.features, None, model_fn.ModeKeys.PREDICT,\n",
        "      estimator.config)\n",
        "  # pylint: enable=protected-access\n",
        "  export_outputs = estimator_spec.export_outputs\n",
        "  export_output = export_outputs.get(output_key)\n",
        "  if export_output is None:\n",
        "    raise KeyError('output_key must be one of {}; got {}'.format(\n",
        "        export_outputs.keys(), output_key))\n",
        "  return export_output.as_signature_def(serving_input_receiver.receiver_tensors)\n",
        "\n",
        "\n",
        "class CoreEstimatorPredictor(predictor.Predictor):\n",
        "  \"\"\"A `Predictor` constructed from an `learn.python.estimator.Estimator`.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               estimator,\n",
        "               serving_input_receiver_fn,\n",
        "               output_key=None,\n",
        "               graph=None,\n",
        "               config=None):\n",
        "    \"\"\"Initialize a `CoreEstimatorPredictor`.\n",
        "    Args:\n",
        "      estimator: an instance of `learn.python.estimator.Estimator`.\n",
        "      serving_input_receiver_fn: a function that takes no arguments and returns\n",
        "        an instance of `ServingInputReceiver` compatible with `estimator`.\n",
        "      output_key: Optional string specifying the export output to use. If\n",
        "        `None`, then `DEFAULT_SERVING_SIGNATURE_DEF_KEY` is used.\n",
        "      graph: Optional. The Tensorflow `graph` in which prediction should be\n",
        "        done.\n",
        "      config: `ConfigProto` proto used to configure the session.\n",
        "    \"\"\"\n",
        "    self._graph = graph or ops.Graph()\n",
        "    with self._graph.as_default():\n",
        "      serving_input_receiver = serving_input_receiver_fn()\n",
        "      signature_def = _get_signature_def(\n",
        "          serving_input_receiver, estimator, output_key)\n",
        "      checkpoint_dir = estimator.model_dir\n",
        "      self._session = monitored_session.MonitoredSession(\n",
        "          session_creator=monitored_session.ChiefSessionCreator(\n",
        "              config=config,\n",
        "              checkpoint_dir=checkpoint_dir))\n",
        "\n",
        "    feed_tensor_info = signature_def.inputs\n",
        "    self._feed_tensors = {k: self._graph.get_tensor_by_name(v.name)\n",
        "                          for k, v in feed_tensor_info.items()}\n",
        "    fetch_tensor_info = signature_def.outputs\n",
        "    self._fetch_tensors = {k: self._graph.get_tensor_by_name(v.name)\n",
        "                           for k, v in fetch_tensor_info.items()}"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting core_estimator_predictor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPwJ2jXjVIAI",
        "outputId": "d6546098-ddb5-497e-c1a5-9c93850f5a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#make saved_model_predictor script\n",
        "%%writefile saved_model_predictor.py\n",
        "\n",
        "\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"A `Predictor` constructed from a `SavedModel`.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import logging\n",
        "\n",
        "import predictor_factories\n",
        "import predictor\n",
        "#from tensorflow.contrib.saved_model.python.saved_model import reader\n",
        "import contrib_reader as reader\n",
        "from tensorflow.python.client import session\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.saved_model import loader\n",
        "from tensorflow.python.saved_model import signature_constants\n",
        "\n",
        "\n",
        "DEFAULT_TAGS = 'serve'\n",
        "\n",
        "_DEFAULT_INPUT_ALTERNATIVE_FORMAT = 'default_input_alternative:{}'\n",
        "\n",
        "\n",
        "def get_meta_graph_def(saved_model_dir, tags):\n",
        "  \"\"\"Gets `MetaGraphDef` from a directory containing a `SavedModel`.\n",
        "  Returns the `MetaGraphDef` for the given tag-set and SavedModel directory.\n",
        "  Args:\n",
        "    saved_model_dir: Directory containing the SavedModel.\n",
        "    tags: Comma separated list of tags used to identify the correct\n",
        "      `MetaGraphDef`.\n",
        "  Raises:\n",
        "    ValueError: An error when the given tags cannot be found.\n",
        "  Returns:\n",
        "    A `MetaGraphDef` corresponding to the given tags.\n",
        "  \"\"\"\n",
        "  saved_model = reader.read_saved_model(saved_model_dir)\n",
        "  set_of_tags = set([tag.strip() for tag in tags.split(',')])\n",
        "  for meta_graph_def in saved_model.meta_graphs:\n",
        "    if set(meta_graph_def.meta_info_def.tags) == set_of_tags:\n",
        "      return meta_graph_def\n",
        "  raise ValueError('Could not find MetaGraphDef with tags {}'.format(tags))\n",
        "\n",
        "\n",
        "def _get_signature_def(signature_def_key, export_dir, tags):\n",
        "  \"\"\"Construct a `SignatureDef` proto.\"\"\"\n",
        "  signature_def_key = (\n",
        "      signature_def_key or\n",
        "      signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY)\n",
        "\n",
        "  metagraph_def = get_meta_graph_def(export_dir, tags)\n",
        "\n",
        "  try:\n",
        "    signature_def = metagraph_def.signature_def[signature_def_key]\n",
        "  except KeyError as e:\n",
        "    formatted_key = _DEFAULT_INPUT_ALTERNATIVE_FORMAT.format(\n",
        "        signature_def_key)\n",
        "    try:\n",
        "      signature_def = metagraph_def.signature_def[formatted_key]\n",
        "    except KeyError:\n",
        "      raise ValueError(\n",
        "          'Got signature_def_key \"{}\". Available signatures are {}. '\n",
        "          'Original error:\\n{}'.format(\n",
        "              signature_def_key, list(metagraph_def.signature_def), e))\n",
        "    logging.warning('Could not find signature def \"%s\". '\n",
        "                    'Using \"%s\" instead', signature_def_key, formatted_key)\n",
        "  return signature_def\n",
        "\n",
        "\n",
        "def _check_signature_arguments(signature_def_key,\n",
        "                               signature_def,\n",
        "                               input_names,\n",
        "                               output_names):\n",
        "  \"\"\"Validates signature arguments for `SavedModelPredictor`.\"\"\"\n",
        "  signature_def_key_specified = signature_def_key is not None\n",
        "  signature_def_specified = signature_def is not None\n",
        "  input_names_specified = input_names is not None\n",
        "  output_names_specified = output_names is not None\n",
        "  if input_names_specified != output_names_specified:\n",
        "    raise ValueError(\n",
        "        'input_names and output_names must both be specified or both be '\n",
        "        'unspecified.'\n",
        "    )\n",
        "\n",
        "  if (signature_def_key_specified + signature_def_specified +\n",
        "      input_names_specified > 1):\n",
        "    raise ValueError(\n",
        "        'You must specify at most one of signature_def_key OR signature_def OR'\n",
        "        '(input_names AND output_names).'\n",
        "    )\n",
        "\n",
        "\n",
        "class SavedModelPredictor(predictor.Predictor):\n",
        "  \"\"\"A `Predictor` constructed from a `SavedModel`.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               export_dir,\n",
        "               signature_def_key=None,\n",
        "               signature_def=None,\n",
        "               input_names=None,\n",
        "               output_names=None,\n",
        "               tags=None,\n",
        "               graph=None,\n",
        "               config=None):\n",
        "    \"\"\"Initialize a `CoreEstimatorPredictor`.\n",
        "    Args:\n",
        "      export_dir: a path to a directory containing a `SavedModel`.\n",
        "      signature_def_key: Optional string specifying the signature to use. If\n",
        "        `None`, then `DEFAULT_SERVING_SIGNATURE_DEF_KEY` is used. Only one of\n",
        "        `signature_def_key` and `signature_def` should be specified.\n",
        "      signature_def: A `SignatureDef` proto specifying the inputs and outputs\n",
        "        for prediction. Only one of `signature_def_key` and `signature_def`\n",
        "        should be specified.\n",
        "      input_names: A dictionary mapping strings to `Tensor`s in the `SavedModel`\n",
        "        that represent the input. The keys can be any string of the user's\n",
        "        choosing.\n",
        "      output_names: A dictionary mapping strings to `Tensor`s in the\n",
        "        `SavedModel` that represent the output. The keys can be any string of\n",
        "        the user's choosing.\n",
        "      tags: Optional. Comma separated list of tags that will be used to retrieve\n",
        "        the correct `SignatureDef`. Defaults to `DEFAULT_TAGS`.\n",
        "      graph: Optional. The Tensorflow `graph` in which prediction should be\n",
        "        done.\n",
        "      config: `ConfigProto` proto used to configure the session.\n",
        "    Raises:\n",
        "      ValueError: If more than one of signature_def_key OR signature_def OR\n",
        "        (input_names AND output_names) is specified.\n",
        "    \"\"\"\n",
        "    _check_signature_arguments(\n",
        "        signature_def_key, signature_def, input_names, output_names)\n",
        "    tags = tags or DEFAULT_TAGS\n",
        "    self._graph = graph or ops.Graph()\n",
        "\n",
        "    with self._graph.as_default():\n",
        "      self._session = session.Session(config=config)\n",
        "      loader.load(self._session, tags.split(','), export_dir)\n",
        "\n",
        "    if input_names is None:\n",
        "      if signature_def is None:\n",
        "        signature_def = _get_signature_def(signature_def_key, export_dir, tags)\n",
        "      input_names = {k: v.name for k, v in signature_def.inputs.items()}\n",
        "      output_names = {k: v.name for k, v in signature_def.outputs.items()}\n",
        "\n",
        "    self._feed_tensors = {k: self._graph.get_tensor_by_name(v)\n",
        "                          for k, v in input_names.items()}\n",
        "    self._fetch_tensors = {k: self._graph.get_tensor_by_name(v)\n",
        "                           for k, v in output_names.items()}\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting saved_model_predictor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q8CnmeAXtNb",
        "outputId": "d91b39e7-894b-4bb9-ab5e-eafc5fdbf471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#make script for tensorflow.contrib.saved_model.python.saved_model.reader\n",
        "%%writefile contrib_reader.py\n",
        "\n",
        "\n",
        "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"SavedModel functionality to read a SavedModel from disk.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "from google.protobuf import message\n",
        "from google.protobuf import text_format\n",
        "from tensorflow.core.protobuf import saved_model_pb2\n",
        "from tensorflow.python.lib.io import file_io\n",
        "from tensorflow.python.saved_model import constants\n",
        "from tensorflow.python.util import compat\n",
        "\n",
        "\n",
        "def read_saved_model(saved_model_dir):\n",
        "  \"\"\"Reads the savedmodel.pb or savedmodel.pbtxt file containing `SavedModel`.\n",
        "  Args:\n",
        "    saved_model_dir: Directory containing the SavedModel file.\n",
        "  Returns:\n",
        "    A `SavedModel` protocol buffer.\n",
        "  Raises:\n",
        "    IOError: If the file does not exist, or cannot be successfully parsed.\n",
        "  \"\"\"\n",
        "  # Build the path to the SavedModel in pbtxt format.\n",
        "  path_to_pbtxt = os.path.join(\n",
        "      compat.as_bytes(saved_model_dir),\n",
        "      compat.as_bytes(constants.SAVED_MODEL_FILENAME_PBTXT))\n",
        "  # Build the path to the SavedModel in pb format.\n",
        "  path_to_pb = os.path.join(\n",
        "      compat.as_bytes(saved_model_dir),\n",
        "      compat.as_bytes(constants.SAVED_MODEL_FILENAME_PB))\n",
        "\n",
        "  # Ensure that the SavedModel exists at either path.\n",
        "  if not file_io.file_exists(path_to_pbtxt) and not file_io.file_exists(\n",
        "      path_to_pb):\n",
        "    raise IOError(\"SavedModel file does not exist at: %s\" % saved_model_dir)\n",
        "\n",
        "  # Parse the SavedModel protocol buffer.\n",
        "  saved_model = saved_model_pb2.SavedModel()\n",
        "  if file_io.file_exists(path_to_pb):\n",
        "    try:\n",
        "      file_content = file_io.FileIO(path_to_pb, \"rb\").read()\n",
        "      saved_model.ParseFromString(file_content)\n",
        "      return saved_model\n",
        "    except message.DecodeError as e:\n",
        "      raise IOError(\"Cannot parse file %s: %s.\" % (path_to_pb, str(e)))\n",
        "  elif file_io.file_exists(path_to_pbtxt):\n",
        "    try:\n",
        "      file_content = file_io.FileIO(path_to_pbtxt, \"rb\").read()\n",
        "      text_format.Merge(file_content.decode(\"utf-8\"), saved_model)\n",
        "      return saved_model\n",
        "    except text_format.ParseError as e:\n",
        "      raise IOError(\"Cannot parse file %s: %s.\" % (path_to_pbtxt, str(e)))\n",
        "  else:\n",
        "    raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n",
        "                  (saved_model_dir, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
        "                   constants.SAVED_MODEL_FILENAME_PB))\n",
        "\n",
        "\n",
        "def get_saved_model_tag_sets(saved_model_dir):\n",
        "  \"\"\"Retrieves all the tag-sets available in the SavedModel.\n",
        "  Args:\n",
        "    saved_model_dir: Directory containing the SavedModel.\n",
        "  Returns:\n",
        "    String representation of all tag-sets in the SavedModel.\n",
        "  \"\"\"\n",
        "  saved_model = read_saved_model(saved_model_dir)\n",
        "  all_tags = []\n",
        "  for meta_graph_def in saved_model.meta_graphs:\n",
        "    all_tags.append(list(meta_graph_def.meta_info_def.tags))\n",
        "  return all_tags\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting contrib_reader.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8FarB--uB8G",
        "outputId": "16cdf516-5320-4bc4-ff3f-407f153cb509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#had to edit to make it work with different tensorflow versions\n",
        "%%writefile sh_deploy.py\n",
        "\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.compat.v1 as tf\n",
        "#from tensorflow.contrib import predictor\n",
        "import predictor_factories\n",
        "import predictor\n",
        "\n",
        "import tensorflow_hub\n",
        "\n",
        "from dltk.io.augmentation import extract_random_example_array\n",
        "\n",
        "from sh_abstract_reader import Reader\n",
        "\n",
        "import reader \n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "READER_PARAMS = {'extract_examples': False}\n",
        "N_VALIDATION_SUBJECTS = 28\n",
        "\n",
        "\n",
        "def predict(args):\n",
        "    # Read in the csv with the file names you would want to predict on\n",
        "    file_names = pd.read_csv(\n",
        "        args.csv,\n",
        "        dtype=object,\n",
        "        keep_default_na=False,\n",
        "        na_values=[]).to_numpy()    #had to change to to_numpy\n",
        "\n",
        "    # We trained on the first 4 subjects, so we predict on the rest\n",
        "    file_names = file_names[-N_VALIDATION_SUBJECTS:]\n",
        "\n",
        "    # From the model_path, parse the latest saved model and restore a\n",
        "    # predictor from it\n",
        "    export_dir = [os.path.join(args.model_path, o) for o in sorted(\n",
        "        os.listdir(args.model_path)) if os.path.isdir(\n",
        "        os.path.join(args.model_path, o)) and o.isdigit()][-1]\n",
        "\n",
        "    print('Loading from {}'.format(export_dir))\n",
        "    my_predictor = predictor_factories.from_saved_model(export_dir)\n",
        "\n",
        "    # Iterate through the files, predict on the full volumes and compute a Dice\n",
        "    # coefficient\n",
        "    mae = []\n",
        "    for output in reader.read_fn(file_references=file_names,\n",
        "                          mode=tf.estimator.ModeKeys.EVAL,\n",
        "                          params=READER_PARAMS):\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Parse the read function output and add a dummy batch dimension as\n",
        "        # required\n",
        "        img = output['features']['x']\n",
        "        lbl = output['labels']['y']\n",
        "        test_id = output['img_id']\n",
        "\n",
        "        # We know, that the training input shape of [64, 96, 96] will work with\n",
        "        # our model strides, so we collect several crops of the test image and\n",
        "        # average the predictions. Alternatively, we could pad or crop the input\n",
        "        # to any shape that is compatible with the resolution scales of the\n",
        "        # model:\n",
        "\n",
        "        num_crop_predictions = 4\n",
        "        crop_batch = extract_random_example_array(\n",
        "            image_list=img,\n",
        "            example_size=[64, 96, 96],\n",
        "            n_examples=num_crop_predictions)\n",
        "\n",
        "        y_ = my_predictor.session.run(\n",
        "            fetches=my_predictor._fetch_tensors['logits'],\n",
        "            feed_dict={my_predictor._feed_tensors['x']: crop_batch})\n",
        "\n",
        "        # Average the predictions on the cropped test inputs:\n",
        "        y_ = np.mean(y_)\n",
        "\n",
        "        # Calculate the absolute error for this subject\n",
        "        mae.append(np.abs(y_ - lbl))\n",
        "\n",
        "        # Print outputs\n",
        "        print('id={}; pred={:0.2f} yrs; true={:0.2f} yrs; run time={:0.2f} s; '\n",
        "              ''.format(test_id, y_, lbl[0], time.time() - t0))\n",
        "    print('mean absolute err={:0.3f} yrs'.format(np.mean(mae)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set up argument parser\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='IXI HH example age regression deploy script')\n",
        "    parser.add_argument('--verbose', default=False, action='store_true')\n",
        "    parser.add_argument('--cuda_devices', '-c', default='0')\n",
        "\n",
        "    parser.add_argument('--model_path', '-p',\n",
        "                        default='/content/IXI_HH_age_regression')\n",
        "    parser.add_argument('--csv', default='/content/IXI_HH_age_regression/demographic_HH.csv')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Set verbosity\n",
        "    if args.verbose:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "        tf.logging.set_verbosity(tf.logging.INFO)\n",
        "    else:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "    # GPU allocation options\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_devices\n",
        "\n",
        "    # Call training\n",
        "    predict(args)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting sh_deploy.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTdIcngjm3KC",
        "outputId": "70c57e71-d258-4157-9be3-909fb268fcda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "#run the deploy script\n",
        "#this should work now....it does!!!!!\n",
        "\n",
        "!python -u /content/sh_deploy.py --model_path '/content/IXI_HH_age_regression/'  --csv /content/demographic_HH.csv --verbose"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-11 21:03:52.175370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Loading from /content/IXI_HH_age_regression/1510857419\n",
            "2020-10-11 21:03:53.761889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-11 21:03:53.770552: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-11 21:03:53.770604: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5f6805a46636): /proc/driver/nvidia/version does not exist\n",
            "2020-10-11 21:03:53.777649: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200185000 Hz\n",
            "2020-10-11 21:03:53.777890: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f10a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-11 21:03:53.777937: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From /content/saved_model_predictor.py:152: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /content/IXI_HH_age_regression/1510857419/variables/variables\n",
            "/usr/local/lib/python3.6/dist-packages/dltk/io/augmentation.py:284: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  ex_image = image_list[j][slicer][np.newaxis]\n",
            "id=IXI566; pred=38.66 yrs; true=42.97 yrs; run time=3.90 s; \n",
            "mean absolute err=4.314 yrs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHrtbhb3m3KE"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1SIeF0Hm3KJ"
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0ULhG8m3cV2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}